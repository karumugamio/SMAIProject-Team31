# -*- coding: utf-8 -*-
"""Demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18Wj5OhLFumGmEMSvKR5jYlRh4bdEcK5w
"""

!pip install rouge
from google.colab import drive 
import tensorflow as tf
import warnings
import datautil as util
import RNNHelper as rnnhelper
import nltk
from rouge import Rouge


if __name__ == "__main__":
  drive.mount('/content/gdrive')
	#run()
  
device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name)) 


nltk.download('stopwords')

import csv
import logging
import string

import numpy as np
import pandas as pd

import RNNSeq2SeqModel
import dataprocessing


logging.basicConfig(level=logging.DEBUG,format='%(levelname)s %(message)s')

def debug(arg):
    logging.debug(arg)

def info(arg):
    logging.info(arg)

def warn(arg):
    logging.warn(arg)

    
model = RNNSeq2SeqModel.RNNSeq2SeqModel()

def fetch():
    debug("CSE471 SMAI - Spring 2019 - Project - Team 31")
    
    
    inputDataFileName = 'gdrive/My Drive/movies_data.csv'
    numberbatchFile = 'gdrive/My Drive/numberbatch-en.txt'
    dataprocessing.prepareData(inputDataFileName,numberbatchFile)

def train():
    
    model.loadData(0.2,0.2)
    model.fit()

def validate():
    prectionResult,actualTagline = model.runValidation()
    score = rnnhelper.getScore(prectionResult,actualTagline)
    debug('Rogue score for Validation Set is')
    debug(score)

def runTest():
    prectionResult,actualTagline = model.runTestSet()
    score_test = rnnhelper.getScore(prectionResult,actualTagline)
    debug('Rogue score for Test Set is')
    debug(score_test)

fetch()

train()

def getScore(m_prediction,m_original):

        rouge = Rouge()
        scores = rouge.get_scores(m_prediction,m_original)
        debug('['+m_prediction+']['+m_original+'] = >score is['+str(scores)+']')
        return scores

      
def predictFromList(self,text):
        checkpoint = 'best_model.ckpt'

        loaded_graph = tf.Graph()
        with tf.Session(graph=loaded_graph) as sess:
            # Load saved model
            loader = tf.train.import_meta_graph(checkpoint + '.meta')
            loader.restore(sess, checkpoint)

            input_data = loaded_graph.get_tensor_by_name('input:0')
            predObj = loaded_graph.get_tensor_by_name('predictions:0')
            text_length = loaded_graph.get_tensor_by_name('text_length:0')
            summary_length = loaded_graph.get_tensor_by_name('summary_length:0')
            keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')
    
            #Multiply by batch_size to match the model's input parameters
            predictionsValue = sess.run(predObj, {input_data: [text]*self.batch_size, 
                                      summary_length: [np.random.randint(5,8)], 
                                      text_length: [len(text)]*self.batch_size,
                                      keep_prob: 1.0})[0] 

        # Remove the padding from the tweet
        pad = self.vocab_to_int["<PAD>"] 

        debug('Text')
        debug('  Word Ids:    {}'.format([i for i in text]))
        debug('  Input Words: {}'.format(" ".join([self.int_to_vocab[i] for i in text])))

        debug('Summary')
        debug('  Word Ids:       {}'.format([i for i in predictionsValue if i != pad]))
        debug('  Response Words: {}'.format(" ".join([self.int_to_vocab[i] for i in predictionsValue if i != pad])))
        debug("predict values")
        returnPredict =  " ".join([self.int_to_vocab[i] for i in predictionsValue if i != pad])
        return returnPredict

def getGenerateTagline(self,predictionsValue):
    pad = self.vocab_to_int["<PAD>"] 
    returnPredict =  " ".join([self.int_to_vocab[i] for i in predictionsValue if i != pad])
    return returnPredict      
      
def runValidation(self):
    predictionResults = []
    for index,inputSentence in enumerate(self.sorted_synopsis_validation):
        prectionResult = predictFromList(self,inputSentence)
        predictionResults.append(prectionResult)
        print(inputSentence)
        print(prectionResult)
        
        tag = getGenerateTagline(self,self.sorted_tagline_validation[index])
        score = getScore(prectionResult,tag)

    debug('Validation Completed')
    return predictionResults,self.sorted_tagline_validation

runValidation(model)